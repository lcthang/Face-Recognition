{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Faces recognition example using eigenfaces and SVMs\n",
    "\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    "\n",
    ".. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Expected results for the top 5 most represented people in the dataset:\n",
    "\n",
    "================== ============ ======= ========== =======\n",
    "                   precision    recall  f1-score   support\n",
    "================== ============ ======= ========== =======\n",
    "     Ariel Sharon       0.67      0.92      0.77        13\n",
    "     Colin Powell       0.75      0.78      0.76        60\n",
    "  Donald Rumsfeld       0.78      0.67      0.72        27\n",
    "    George W Bush       0.86      0.86      0.86       146\n",
    "Gerhard Schroeder       0.76      0.76      0.76        25\n",
    "      Hugo Chavez       0.67      0.67      0.67        15\n",
    "       Tony Blair       0.81      0.69      0.75        36\n",
    "\n",
    "      avg / total       0.80      0.80      0.80       322\n",
    "================== ============ ======= ========== =======\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#from sklearn.cross_validation import KFold\n",
    "import numpy as np\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data, if not already on disk and load it as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n",
      "height:  50\n",
      "width:  37\n"
     ]
    }
   ],
   "source": [
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "#X_train = np.load('X_train.npy')\n",
    "#y_train = np.load('y_train.npy')\n",
    "#X_test = np.load('X_test.npy')\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "#n_features = X_train.shape[1]\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "#print(target_names)\n",
    "n_classes = target_names.shape[0]\n",
    "#n_classes = y_train.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)\n",
    "print('height: ', h)\n",
    "print('width: ', w)\n",
    "#print('X_train: ', X_train)\n",
    "#print('y_train: ', y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into a training set and a test set using a stratified k fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "dataset): unsupervised feature extraction / dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 150 eigenfaces from 966 faces\n",
      "done in 0.293s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.026s\n"
     ]
    }
   ],
   "source": [
    "n_components = 150\n",
    "#h = 50\n",
    "#w = 37\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "      % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a SVM classification model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 76.883s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.005, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = [\n",
    "{'C': [1e3, 5e3, 1e4, 5e4, 1e5], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "]\n",
    "clf = GridSearchCV(SVC(class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "\n",
    "fo = open('y_test_2.txt', 'w')\n",
    "fo.write(str(clf.best_estimator_) + \"\\n\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitative evaluation of the model quality on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting people's names on the test set\n",
      "done in 0.057s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.75      0.46      0.57        13\n",
      "     Colin Powell       0.79      0.87      0.83        60\n",
      "  Donald Rumsfeld       0.89      0.59      0.71        27\n",
      "    George W Bush       0.84      0.98      0.91       146\n",
      "Gerhard Schroeder       0.95      0.80      0.87        25\n",
      "      Hugo Chavez       0.89      0.53      0.67        15\n",
      "       Tony Blair       0.97      0.81      0.88        36\n",
      "\n",
      "      avg / total       0.86      0.85      0.84       322\n",
      "\n",
      "0,3\n",
      "1,3\n",
      "2,6\n",
      "3,3\n",
      "4,3\n",
      "5,3\n",
      "6,4\n",
      "7,1\n",
      "8,3\n",
      "9,3\n",
      "10,3\n",
      "11,3\n",
      "12,3\n",
      "13,6\n",
      "14,3\n",
      "15,3\n",
      "16,3\n",
      "17,3\n",
      "18,3\n",
      "19,4\n",
      "20,1\n",
      "21,3\n",
      "22,3\n",
      "23,3\n",
      "24,3\n",
      "25,1\n",
      "26,1\n",
      "27,3\n",
      "28,3\n",
      "29,3\n",
      "30,2\n",
      "31,3\n",
      "32,3\n",
      "33,3\n",
      "34,3\n",
      "35,3\n",
      "36,3\n",
      "37,1\n",
      "38,3\n",
      "39,1\n",
      "40,3\n",
      "41,1\n",
      "42,3\n",
      "43,1\n",
      "44,1\n",
      "45,1\n",
      "46,4\n",
      "47,3\n",
      "48,3\n",
      "49,3\n",
      "50,3\n",
      "51,3\n",
      "52,0\n",
      "53,3\n",
      "54,6\n",
      "55,2\n",
      "56,3\n",
      "57,3\n",
      "58,5\n",
      "59,3\n",
      "60,1\n",
      "61,1\n",
      "62,0\n",
      "63,4\n",
      "64,3\n",
      "65,1\n",
      "66,6\n",
      "67,4\n",
      "68,1\n",
      "69,3\n",
      "70,1\n",
      "71,6\n",
      "72,3\n",
      "73,3\n",
      "74,3\n",
      "75,2\n",
      "76,1\n",
      "77,6\n",
      "78,4\n",
      "79,4\n",
      "80,3\n",
      "81,0\n",
      "82,4\n",
      "83,3\n",
      "84,3\n",
      "85,3\n",
      "86,3\n",
      "87,3\n",
      "88,3\n",
      "89,3\n",
      "90,3\n",
      "91,6\n",
      "92,3\n",
      "93,1\n",
      "94,1\n",
      "95,3\n",
      "96,1\n",
      "97,1\n",
      "98,6\n",
      "99,6\n",
      "100,3\n",
      "101,1\n",
      "102,3\n",
      "103,1\n",
      "104,3\n",
      "105,1\n",
      "106,3\n",
      "107,3\n",
      "108,3\n",
      "109,1\n",
      "110,4\n",
      "111,1\n",
      "112,3\n",
      "113,3\n",
      "114,3\n",
      "115,1\n",
      "116,3\n",
      "117,4\n",
      "118,1\n",
      "119,3\n",
      "120,1\n",
      "121,3\n",
      "122,3\n",
      "123,0\n",
      "124,3\n",
      "125,4\n",
      "126,4\n",
      "127,3\n",
      "128,1\n",
      "129,3\n",
      "130,6\n",
      "131,6\n",
      "132,6\n",
      "133,3\n",
      "134,3\n",
      "135,4\n",
      "136,3\n",
      "137,3\n",
      "138,1\n",
      "139,6\n",
      "140,2\n",
      "141,2\n",
      "142,5\n",
      "143,1\n",
      "144,3\n",
      "145,5\n",
      "146,1\n",
      "147,3\n",
      "148,3\n",
      "149,1\n",
      "150,1\n",
      "151,1\n",
      "152,1\n",
      "153,3\n",
      "154,3\n",
      "155,3\n",
      "156,6\n",
      "157,3\n",
      "158,1\n",
      "159,3\n",
      "160,6\n",
      "161,5\n",
      "162,5\n",
      "163,1\n",
      "164,3\n",
      "165,1\n",
      "166,5\n",
      "167,1\n",
      "168,3\n",
      "169,3\n",
      "170,1\n",
      "171,1\n",
      "172,6\n",
      "173,1\n",
      "174,5\n",
      "175,6\n",
      "176,3\n",
      "177,2\n",
      "178,2\n",
      "179,3\n",
      "180,3\n",
      "181,3\n",
      "182,3\n",
      "183,1\n",
      "184,3\n",
      "185,3\n",
      "186,3\n",
      "187,3\n",
      "188,3\n",
      "189,2\n",
      "190,3\n",
      "191,2\n",
      "192,3\n",
      "193,2\n",
      "194,6\n",
      "195,3\n",
      "196,3\n",
      "197,6\n",
      "198,3\n",
      "199,6\n",
      "200,3\n",
      "201,2\n",
      "202,1\n",
      "203,2\n",
      "204,3\n",
      "205,1\n",
      "206,6\n",
      "207,2\n",
      "208,3\n",
      "209,1\n",
      "210,3\n",
      "211,4\n",
      "212,3\n",
      "213,3\n",
      "214,3\n",
      "215,3\n",
      "216,3\n",
      "217,3\n",
      "218,3\n",
      "219,1\n",
      "220,3\n",
      "221,3\n",
      "222,3\n",
      "223,1\n",
      "224,6\n",
      "225,3\n",
      "226,3\n",
      "227,3\n",
      "228,1\n",
      "229,3\n",
      "230,3\n",
      "231,3\n",
      "232,1\n",
      "233,0\n",
      "234,3\n",
      "235,1\n",
      "236,6\n",
      "237,3\n",
      "238,3\n",
      "239,3\n",
      "240,3\n",
      "241,4\n",
      "242,2\n",
      "243,3\n",
      "244,3\n",
      "245,0\n",
      "246,3\n",
      "247,3\n",
      "248,3\n",
      "249,3\n",
      "250,4\n",
      "251,3\n",
      "252,3\n",
      "253,1\n",
      "254,3\n",
      "255,4\n",
      "256,3\n",
      "257,1\n",
      "258,6\n",
      "259,0\n",
      "260,3\n",
      "261,3\n",
      "262,2\n",
      "263,1\n",
      "264,3\n",
      "265,6\n",
      "266,3\n",
      "267,1\n",
      "268,3\n",
      "269,6\n",
      "270,1\n",
      "271,1\n",
      "272,3\n",
      "273,3\n",
      "274,6\n",
      "275,3\n",
      "276,3\n",
      "277,3\n",
      "278,3\n",
      "279,3\n",
      "280,1\n",
      "281,1\n",
      "282,3\n",
      "283,3\n",
      "284,1\n",
      "285,0\n",
      "286,3\n",
      "287,3\n",
      "288,3\n",
      "289,4\n",
      "290,4\n",
      "291,3\n",
      "292,5\n",
      "293,3\n",
      "294,3\n",
      "295,1\n",
      "296,4\n",
      "297,5\n",
      "298,3\n",
      "299,4\n",
      "300,3\n",
      "301,6\n",
      "302,6\n",
      "303,2\n",
      "304,1\n",
      "305,3\n",
      "306,2\n",
      "307,3\n",
      "308,1\n",
      "309,3\n",
      "310,3\n",
      "311,3\n",
      "312,1\n",
      "313,6\n",
      "314,3\n",
      "315,3\n",
      "316,3\n",
      "317,1\n",
      "318,3\n",
      "319,3\n",
      "320,3\n",
      "321,2\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "#print(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "#print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
    "\n",
    "fo.write(\"ImageId,PredictedClass\"+\"\\n\")\n",
    "for i in range(y_pred.size):\n",
    "    fo.write(str(i) + \",\" + str(y_pred[i]) + \"\\n\")\n",
    "    print(str(i) + \",\" + str(y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitative evaluation of the predictions using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "     #Helper function to plot a gallery of portraits\n",
    "#    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "#    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "#    for i in range(n_row * n_col):\n",
    "#        plt.subplot(n_row, n_col, i + 1)\n",
    "#        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "#        plt.title(titles[i], size=12)\n",
    "#        plt.xticks(())\n",
    "#        plt.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "#def title(y_pred, y_test, target_names, i):\n",
    "#    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "#    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "#    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "#prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "#                     for i in range(y_pred.shape[0])]\n",
    "\n",
    "#plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "#eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "#plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
